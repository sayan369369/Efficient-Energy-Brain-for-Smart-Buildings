# âš¡ Efficient Energy Brain for Smart Buildings

**Team Project | Department of Computer Science, RKMVERI**  
**Instructor:** Br. Bhaswarachaitanya (Tamal Maharaj)  
**Team Members:**  
- ğŸ§  **Jahar Kumar Paul (B2430049)** â€” Machine & Deep Learning  
- ğŸ¤– **Ayan Kumar Batabyal (B2530074)** â€” Reinforcement Learning  
- ğŸ”¬ **Sayan Goswami (B2530098)** â€” Reinforcement Learning, System Integration

---

## ğŸ“„ Project Report

[ğŸ“¥ **Download Project Proposal (PDF)**](https://github.com/sayan369369/Efficient-Energy-Brain-for-Smart-Buildings/blob/main/Infinity_ProjectProposal.pdf)

---
## ğŸŒ Overview

> â€œWe do not inherit the Earth from our ancestors; we borrow it from our children.â€ â€” *American Proverb*

The **Efficient Energy Brain** is an intelligent control framework designed to optimize energy consumption in smart buildings while maintaining occupant comfort.  
By integrating **Machine Learning (ML)** and **Reinforcement Learning (RL)**, it dynamically predicts, adapts, and optimizes energy usage â€” particularly in **HVAC (Heating, Ventilation, and Air Conditioning)** systems.

Our vision is to make buildings truly intelligent â€” **sustainable, autonomous, and energy-efficient**.

---

## ğŸ’¡ Motivation

Energy consumption in large buildings continues to increase rapidly.  
Among all utilities, **HVAC systems account for a major share** of total energy use.

This project addresses the need for:
- ğŸŒ± Sustainable energy consumption  
- ğŸŒ¡ï¸ Thermal comfort management  
- ğŸ¤– Autonomous, adaptive decision-making  

---

## ğŸ§  Proposed Framework

The system operates in **two key phases:**

### ğŸ”¹ Phase 1 â€” Deep Learning (Prediction)
A **Multi-Output Deep Neural Network (DNN)** is trained on building data to predict:
- Indoor and outdoor temperature  
- Occupancy levels  
- Energy demand and cost  

**Inputs:** Room size, number of occupants, outdoor/indoor temperature, energy price, desired comfort level  
**Outputs:** Short-term forecasts (e.g., 30-minute window) for optimal control decisions.

---

### ğŸ”¹ Phase 2 â€” Reinforcement Learning (Adaptive Control)
The RL agent continuously interacts with the environment to adjust HVAC parameters.

- Observes real-time data + predictions from the DL model  
- Adapts temperature and fan speed automatically  
- Applies **reward** for energy efficiency and **penalty** for discomfort or manual overrides  
- Learns continuously from new data every few minutes  

**Example:**  
If occupancy unexpectedly increases, the RL model increases cooling capacity while minimizing excess energy use.

---

## ğŸ”„ Continuous Learning and Updates

Every few minutes, the system updates:
- Deep Learning weights (based on environmental feedback)  
- Reinforcement Learning policy (based on comfort-energy trade-off)  

This ensures the **Energy Brain** evolves dynamically, reflecting real-world conditions in near real time.

---

## âš™ï¸ Loophole & Solution

**Challenge:** Who sets the *initial AC temperature* before control begins?  
**Solution:**  
A lightweight, pre-trained **RL initialization model** determines the first setting automatically â€” ensuring consistent, efficient start-up even before adaptive control begins.

---

## ğŸ¯ Outcomes

- ğŸ”‹ Reduction in total energy consumption  
- ğŸŒ¡ï¸ Maintained optimal indoor comfort  
- ğŸ¤– Autonomous and scalable system design  
- â™»ï¸ Step toward sustainable smart buildings  

This hybrid ML + RL approach functions as an **Energy Brain** â€” enabling intelligent energy decisions.

---



